{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151db33",
   "metadata": {},
   "source": [
    "### 1. Data Exploration\n",
    "Before we work on the data, we want to explore and find out some information and scope about the data that we are working with. Additionally, it is important for us to deal with any dirty data, for example, missing values and invalid values. \n",
    "\n",
    "Having an appreciation and understanding of the data will enable us to interpret the results of any model well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242557e",
   "metadata": {},
   "source": [
    "#### Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('training.csv')\n",
    "test_set = pd.read_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15d820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ce6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0183fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(training_set['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6249d72",
   "metadata": {},
   "source": [
    "Taking a look at the first 5 observations at both training and test datasets provided to us, we observe that there is a class variable, and 9 other numerical variables labelled b1-b9. We are not entirely sure what these covariates represent because we are not given much information about them, so we'll just take them as they are. \n",
    "\n",
    "Also, there are also prediction variables somehow included in the dataset, which might not be relevant to our study, so we'll omit them as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask function to omit pred variables\n",
    "def var_omit(dataset):\n",
    "    mask = [] # creates an empty list\n",
    "    for col in training_set:\n",
    "        if not col.startswith('pred_minus_obs'): \n",
    "            mask.append(col) # add column to list if it does not start with pred\n",
    "    data = dataset[mask] # applies the mask \n",
    "    return(data) # return the new dataset with appropriate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101088c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set = var_omit(training_set), var_omit(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158772d",
   "metadata": {},
   "source": [
    "A look at the datasets with omitted pred variables looks ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd86da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c40a3",
   "metadata": {},
   "source": [
    "#### Data Visualisation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37c3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set.dtypes\n",
    "datasets = [training_set, test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b677d1",
   "metadata": {},
   "source": [
    "We observe that the datatypes for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091ef6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for any missing values in the datasets (train and test), vector dimensions have to match\n",
    "def missing_value_test(datasets):\n",
    "    missing_value = np.array(datasets[0].isnull().sum())\n",
    "    colnames = datasets[0].columns\n",
    "    for data in datasets[1:]:\n",
    "        dm = np.array(data.isnull().sum())\n",
    "        missing_value = np.stack((missing_value, dm))\n",
    "    df = pd.DataFrame(missing_value, columns=colnames, index=['train','test'])\n",
    "    return(df)\n",
    "\n",
    "missing_value_test(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d909503",
   "metadata": {},
   "source": [
    "Data for both the training set and the test set look to be okay for now, no missing values so given data is clean. Hence, there is no need to deal with or impute missing data. \n",
    "\n",
    "Next, we use the describe method to look at some summary statistics of the two datasets. This will give us a rough idea of any huge outliers in the data, if any. As of now, no observable disparity of data between the 2 sets, and the min and max values look to be alright with no outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edd60d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739e047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8577e1",
   "metadata": {},
   "source": [
    "Perhaps we can better visualise this using a boxplot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15, 7))\n",
    "ax[0].boxplot(np.array(training_set)[:,1:])\n",
    "ax[1].boxplot(np.array(test_set)[:,1:])\n",
    "ax[0].set_title('Training Set')\n",
    "ax[1].set_title('Test Set')\n",
    "ax[0].set_ylim(0, 200)\n",
    "ax[1].set_ylim(0, 200)\n",
    "ax[0].grid(True)\n",
    "ax[1].grid(True)\n",
    "fig.suptitle('Boxplot of b1-b9 variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08254efa",
   "metadata": {},
   "source": [
    "By looking at the boxplots of the numerical variables, for both the training and the test sets, we are able to tell that there are quite a fair few number of outliers that fall outside the IQR range on some of these variables. However, the pattern of the 9 covariates looks acceptable between the 2 sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797aa8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.hist(bins=20, figsize=(20,15))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
